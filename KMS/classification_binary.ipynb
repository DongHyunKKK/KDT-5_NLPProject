{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import os\n",
    "import torch.nn as nn\n",
    "import seaborn\n",
    "import koreanize_matplotlib\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from bareunpy import Tagger\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = './DATA/TABLES/'\n",
    "\n",
    "tables = []\n",
    "names = os.listdir(ROOT)\n",
    "for x in names: tables.append(pd.read_csv(ROOT+x, encoding='utf-8'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, table in enumerate(tables):\n",
    "    tables[idx] = table.melt().reindex(columns=['value', 'variable'])\n",
    "    tables[idx].reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['경상도.csv', '강원도.csv', '전라도.csv', '충청도.csv', '제주도.csv']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TABLETARGET = tables[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_tables = list(zip(tables, names))\n",
    "\n",
    "class TableDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, table):\n",
    "        super().__init__()\n",
    "        self.table = table\n",
    "        self.category = self.table['variable'].astype('category')\n",
    "        self.label = self.category.cat.codes\n",
    "        print(type(self.label), type(self.table), self.label.shape, self.table.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        number = len(self.table)\n",
    "        return number\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 데이터 로드\n",
    "        label = self.label.iloc[idx]\n",
    "        sentence = self.table['value'].iloc[idx]\n",
    "        \n",
    "        return label, sentence\n",
    "        \n",
    "# 토큰화 함수\n",
    "from jamo import h2j, j2hcj\n",
    "def tokenize(iterator, tokenizer):\n",
    "    for label, text in iterator:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "def tokenize_baerun(iterator, tokenizer):\n",
    "    for label, text in iterator:\n",
    "        yield tokenizer.tags('안녕하세요').morphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(표준어    40959\n",
       " 사투리    40639\n",
       " Name: variable, dtype: int64,\n",
       " 사투리    10360\n",
       " 표준어    10040\n",
       " Name: variable, dtype: int64)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = TABLETARGET.sample(frac=0.8)\n",
    "test = TABLETARGET.drop(train.index)\n",
    "\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train.dropna(inplace=True)\n",
    "test.dropna(inplace=True)\n",
    "\n",
    "\n",
    "train['variable'].value_counts(), test['variable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 81598 entries, 0 to 81597\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   value     81598 non-null  object\n",
      " 1   variable  81598 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'> (81598,) (81598, 2)\n",
      "<class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'> (20400,) (20400, 2)\n",
      "<class 'pandas.core.series.Series'> <class 'pandas.core.frame.DataFrame'> (101998,) (101998, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, '구들에 이거 무신 몬지고 구들 다 다까사켜')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 데이터셋 정의\n",
    "gyd_train = TableDataset(train)\n",
    "gyd_test = TableDataset(test)\n",
    "gyd_total = TableDataset(TABLETARGET)\n",
    "\n",
    "\n",
    "gyd_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81598, 2), 81598, (20400, 2))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, gyd_train.__len__(), test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = '<unk>'\n",
    "PAD = '<pad>'\n",
    "\n",
    "# 토큰화 인스턴스 생성 \n",
    "tokenizer = Mecab().morphs\n",
    "\n",
    "\n",
    "API_KEY = 'koba-TXPHP7A-AOWEX4Y-WCTFG3I-RFAISLA'\n",
    "tokenizer_baerun = Tagger(API_KEY, '127.0.0.1', 5757)\n",
    "\n",
    "\n",
    "# tokenizer_baerun = tokenizer_baerun.tags('안녕하세요').morphs()\n",
    "# tokenizer_baerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[271], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 단어사전 생성하기 \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# vocab = build_vocab_from_iterator(tokenize(gyd_train, tokenizer), specials=[UNK, PAD])\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m vocab \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_vocab_from_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_baerun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgyd_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_baerun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mUNK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPAD\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# default unk\u001b[39;00m\n\u001b[1;32m      6\u001b[0m vocab\u001b[38;5;241m.\u001b[39mset_default_index(vocab[UNK])\n",
      "File \u001b[0;32m/media/data/miniconda3/envs/EXAM_DL/lib/python3.9/site-packages/torchtext/vocab/vocab_factory.py:98\u001b[0m, in \u001b[0;36mbuild_vocab_from_iterator\u001b[0;34m(iterator, min_freq, specials, special_first, max_tokens)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mBuild a Vocab from an iterator.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    >>> vocab = build_vocab_from_iterator(yield_tokens(file_path), specials=[\"<unk>\"])\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m counter \u001b[38;5;241m=\u001b[39m Counter()\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tokens \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[1;32m     99\u001b[0m     counter\u001b[38;5;241m.\u001b[39mupdate(tokens)\n\u001b[1;32m    101\u001b[0m specials \u001b[38;5;241m=\u001b[39m specials \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "Cell \u001b[0;32mIn[242], line 31\u001b[0m, in \u001b[0;36mtokenize_baerun\u001b[0;34m(iterator, tokenizer)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_baerun\u001b[39m(iterator, tokenizer):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label, text \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m---> 31\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m안녕하세요\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmorphs()\n",
      "File \u001b[0;32m/media/data/miniconda3/envs/EXAM_DL/lib/python3.9/site-packages/bareunpy/_tagger.py:229\u001b[0m, in \u001b[0;36mTagger.tags\u001b[0;34m(self, phrase, auto_split, auto_spacing, auto_jointing)\u001b[0m\n\u001b[1;32m    227\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(phrase)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_syntax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_spacing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_spacing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_jointing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_jointing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tagged(p, res)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/media/data/miniconda3/envs/EXAM_DL/lib/python3.9/site-packages/bareunpy/_lang_service_client.py:61\u001b[0m, in \u001b[0;36mBareunLanguageServiceClient.analyze_syntax\u001b[0;34m(self, content, domain, auto_split, auto_spacing, auto_jointing)\u001b[0m\n\u001b[1;32m     59\u001b[0m     req\u001b[38;5;241m.\u001b[39mcustom_domain \u001b[38;5;241m=\u001b[39m domain\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     res, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAnalyzeSyntax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/media/data/miniconda3/envs/EXAM_DL/lib/python3.9/site-packages/grpc/_channel.py:1190\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_call\u001b[39m(\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1180\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1186\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[1;32m   1187\u001b[0m     (\n\u001b[1;32m   1188\u001b[0m         state,\n\u001b[1;32m   1189\u001b[0m         call,\n\u001b[0;32m-> 1190\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/media/data/miniconda3/envs/EXAM_DL/lib/python3.9/site-packages/grpc/_channel.py:1157\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1141\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1142\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1143\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context,\n\u001b[1;32m   1156\u001b[0m )\n\u001b[0;32m-> 1157\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:367\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:188\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:182\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:62\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:58\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._interpret_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/tag.pyx.pxi:71\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._BatchOperationTag.event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/operation.pyx.pxi:138\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.ReceiveInitialMetadataOperation.un_c\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi:69\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._metadata\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi:70\u001b[0m, in \u001b[0;36mgenexpr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi:64\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._metadatum\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(_cls, key, value)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 단어사전 생성하기 \n",
    "vocab = build_vocab_from_iterator(tokenize(gyd_train, tokenizer), specials=[UNK, PAD])\n",
    "vocab = build_vocab_from_iterator(tokenize_baerun(gyd_train, tokenizer_baerun), specials=[UNK, PAD])\n",
    "\n",
    "# default unk\n",
    "vocab.set_default_index(vocab[UNK])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 41]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['먹', '것'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 41, 4, 41]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['먹', '것', '이', '것'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(x):\n",
    "    return vocab(tokenizer.morphs(x))\n",
    "\n",
    "# def label_pipeline(x):\n",
    "#     # 데이터셋에서 라벨을 0부터 잡았으므로 그대로 정수 반환\n",
    "#     return int(x)\n",
    "\n",
    "def collate_batch(batch):\n",
    "    labels, text_list, offsets = [], [], [0]\n",
    "    \n",
    "    for label, text in batch:\n",
    "        \n",
    "        labels.append(label)\n",
    "        \n",
    "        processed_text = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        \n",
    "        offsets.append(processed_text.size(0))\n",
    "        \n",
    "        \n",
    "    labels = torch.tensor(labels, dtype=torch.int64).to(DEVICE)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0).to(DEVICE)\n",
    "    text_list = torch.cat(text_list).to(DEVICE)\n",
    "    \n",
    "    return labels, text_list, offsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 10000\n",
    "\n",
    "\n",
    "\n",
    "trainloader = DataLoader(gyd_train, batch_size=BATCHSIZE, collate_fn=collate_batch, num_workers=64)\n",
    "testloader = DataLoader(gyd_test, batch_size=BATCHSIZE, collate_fn=collate_batch, num_workers=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_Class = len(gyd_train.category.cat.categories)\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 15\n",
    "hidden_dim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextStdDia(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_Class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim)\n",
    "        self.rnn = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, 1)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        output, _hidden = self.rnn(embedded)\n",
    "        return self.fc(output)\n",
    "    \n",
    "model = TextStdDia(vocab_size, embed_dim, hidden_dim, num_Class).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import BinaryF1Score, BinaryAccuracy, BinaryConfusionMatrix\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, scheduler):\n",
    "    model.train()\n",
    "    lossagg = []\n",
    "    f1 = BinaryF1Score().to(DEVICE)\n",
    "    cm = BinaryConfusionMatrix().to(DEVICE)\n",
    "    \n",
    "    \n",
    "    for label, text, offsets in iterator:\n",
    "        label = label.unsqueeze(1).float()\n",
    "\n",
    "        predictions = model(text, offsets)\n",
    "        loss = criterion(predictions, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lossagg.append(loss.item())\n",
    "        f1(predictions, label)\n",
    "        cm(predictions, label)\n",
    "        \n",
    "        \n",
    "\n",
    "    scheduler.step(loss)        \n",
    "    print(f\"Train F1 score : {f1.compute()}\")\n",
    "    print(f\"Train Confusion Matrix : \\n{cm.compute()}\")\n",
    "    \n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    lossagg = []\n",
    "    f1 = BinaryF1Score().to(DEVICE)\n",
    "    cm = BinaryConfusionMatrix().to(DEVICE)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for label, text, offsets in iterator:\n",
    "            label = label.unsqueeze(1).float()\n",
    "            \n",
    "            predictions = model(text, offsets)\n",
    "            loss = criterion(predictions, label)\n",
    "            \n",
    "            lossagg.append(loss.item())\n",
    "            f1(predictions, label)\n",
    "            cm(predictions, label)\n",
    "            \n",
    "    print(f\"Test F1 score : {f1.compute()}\")\n",
    "    print(f\"Test Confusion Matrix : \\n{cm.compute()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 병목 증상 설명\n",
    "\n",
    "- 기존 이미지의 경우에는 GPU에서 돌리는 것이 효과적\n",
    "- 하지만 단어 태깅이 CPU 에서 이루어지므로 자연어 처리에서는 CPU가 더 효과적임\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1 score : 0.32678696513175964\n",
      "Train Confusion Matrix : \n",
      "tensor([[31246,  9527],\n",
      "        [30991,  9834]])\n",
      "Test F1 score : 0.6655324697494507\n",
      "Test Confusion Matrix : \n",
      "tensor([[    6, 10220],\n",
      "        [    3, 10171]])\n",
      "Train F1 score : 0.6042546629905701\n",
      "Train Confusion Matrix : \n",
      "tensor([[10706, 30067],\n",
      "        [10134, 30691]])\n",
      "Test F1 score : 0.7527104020118713\n",
      "Test Confusion Matrix : \n",
      "tensor([[5329, 4897],\n",
      "        [1079, 9095]])\n",
      "Train F1 score : 0.5101412534713745\n",
      "Train Confusion Matrix : \n",
      "tensor([[33191,  7582],\n",
      "        [24250, 16575]])\n",
      "Test F1 score : 0.6352049112319946\n",
      "Test Confusion Matrix : \n",
      "tensor([[9960,  266],\n",
      "        [5315, 4859]])\n",
      "Train F1 score : 0.6479852795600891\n",
      "Train Confusion Matrix : \n",
      "tensor([[33012,  7761],\n",
      "        [17539, 23286]])\n",
      "Test F1 score : 0.8859982490539551\n",
      "Test Confusion Matrix : \n",
      "tensor([[8239, 1987],\n",
      "        [ 502, 9672]])\n",
      "Train F1 score : 0.7778144478797913\n",
      "Train Confusion Matrix : \n",
      "tensor([[26090, 14683],\n",
      "        [ 5499, 35326]])\n",
      "Test F1 score : 0.9368729591369629\n",
      "Test Confusion Matrix : \n",
      "tensor([[9327,  899],\n",
      "        [ 416, 9758]])\n",
      "Train F1 score : 0.8045788407325745\n",
      "Train Confusion Matrix : \n",
      "tensor([[31994,  8779],\n",
      "        [ 7439, 33386]])\n",
      "Test F1 score : 0.9625449776649475\n",
      "Test Confusion Matrix : \n",
      "tensor([[9736,  490],\n",
      "        [ 280, 9894]])\n",
      "Train F1 score : 0.8391108512878418\n",
      "Train Confusion Matrix : \n",
      "tensor([[32403,  8370],\n",
      "        [ 5266, 35559]])\n",
      "Test F1 score : 0.971271276473999\n",
      "Test Confusion Matrix : \n",
      "tensor([[ 9747,   479],\n",
      "        [  116, 10058]])\n",
      "Train F1 score : 0.8624463081359863\n",
      "Train Confusion Matrix : \n",
      "tensor([[33153,  7620],\n",
      "        [ 4096, 36729]])\n",
      "Test F1 score : 0.9775628447532654\n",
      "Test Confusion Matrix : \n",
      "tensor([[ 9828,   398],\n",
      "        [   66, 10108]])\n",
      "Train F1 score : 0.8804553151130676\n",
      "Train Confusion Matrix : \n",
      "tensor([[34192,  6581],\n",
      "        [ 3543, 37282]])\n",
      "Test F1 score : 0.9851400852203369\n",
      "Test Confusion Matrix : \n",
      "tensor([[ 9985,   241],\n",
      "        [   64, 10110]])\n",
      "Train F1 score : 0.9007325172424316\n",
      "Train Confusion Matrix : \n",
      "tensor([[35077,  5696],\n",
      "        [ 2706, 38119]])\n",
      "Test F1 score : 0.9818323254585266\n",
      "Test Confusion Matrix : \n",
      "tensor([[ 9920,   306],\n",
      "        [   68, 10106]])\n",
      "Train F1 score : 0.9204072952270508\n",
      "Train Confusion Matrix : \n",
      "tensor([[35901,  4872],\n",
      "        [ 1866, 38959]])\n",
      "Test F1 score : 0.9684816598892212\n",
      "Test Confusion Matrix : \n",
      "tensor([[ 9649,   577],\n",
      "        [   80, 10094]])\n",
      "Train F1 score : 0.9355687499046326\n",
      "Train Confusion Matrix : \n",
      "tensor([[36489,  4284],\n",
      "        [ 1177, 39648]])\n",
      "Test F1 score : 0.955674409866333\n",
      "Test Confusion Matrix : \n",
      "tensor([[ 9468,   758],\n",
      "        [  170, 10004]])\n",
      "Train F1 score : 0.944656252861023\n",
      "Train Confusion Matrix : \n",
      "tensor([[37034,  3739],\n",
      "        [  935, 39890]])\n",
      "Test F1 score : 0.9462754726409912\n",
      "Test Confusion Matrix : \n",
      "tensor([[9338,  888],\n",
      "        [ 240, 9934]])\n",
      "Train F1 score : 0.9498866200447083\n",
      "Train Confusion Matrix : \n",
      "tensor([[37373,  3400],\n",
      "        [  821, 40004]])\n",
      "Test F1 score : 0.9433223605155945\n",
      "Test Confusion Matrix : \n",
      "tensor([[9335,  891],\n",
      "        [ 296, 9878]])\n",
      "Train F1 score : 0.9538277983665466\n",
      "Train Confusion Matrix : \n",
      "tensor([[37732,  3041],\n",
      "        [  831, 39994]])\n",
      "Test F1 score : 0.9475249648094177\n",
      "Test Confusion Matrix : \n",
      "tensor([[9429,  797],\n",
      "        [ 297, 9877]])\n",
      "Train F1 score : 0.9572418332099915\n",
      "Train Confusion Matrix : \n",
      "tensor([[38030,  2743],\n",
      "        [  830, 39995]])\n",
      "Test F1 score : 0.9533753395080566\n",
      "Test Confusion Matrix : \n",
      "tensor([[9524,  702],\n",
      "        [ 267, 9907]])\n",
      "Train F1 score : 0.9601804614067078\n",
      "Train Confusion Matrix : \n",
      "tensor([[38263,  2510],\n",
      "        [  809, 40016]])\n",
      "Test F1 score : 0.9568824172019958\n",
      "Test Confusion Matrix : \n",
      "tensor([[9586,  640],\n",
      "        [ 254, 9920]])\n",
      "Train F1 score : 0.962192714214325\n",
      "Train Confusion Matrix : \n",
      "tensor([[38433,  2340],\n",
      "        [  805, 40020]])\n",
      "Test F1 score : 0.9576009511947632\n",
      "Test Confusion Matrix : \n",
      "tensor([[9607,  619],\n",
      "        [ 259, 9915]])\n",
      "Train F1 score : 0.9636794924736023\n",
      "Train Confusion Matrix : \n",
      "tensor([[38585,  2188],\n",
      "        [  827, 39998]])\n",
      "Test F1 score : 0.9596052169799805\n",
      "Test Confusion Matrix : \n",
      "tensor([[9647,  579],\n",
      "        [ 256, 9918]])\n",
      "Train F1 score : 0.9649133682250977\n",
      "Train Confusion Matrix : \n",
      "tensor([[38689,  2084],\n",
      "        [  825, 40000]])\n",
      "Test F1 score : 0.9606390595436096\n",
      "Test Confusion Matrix : \n",
      "tensor([[9666,  560],\n",
      "        [ 253, 9921]])\n",
      "Train F1 score : 0.9660677313804626\n",
      "Train Confusion Matrix : \n",
      "tensor([[38787,  1986],\n",
      "        [  824, 40001]])\n",
      "Test F1 score : 0.9611673951148987\n",
      "Test Confusion Matrix : \n",
      "tensor([[9686,  540],\n",
      "        [ 261, 9913]])\n",
      "Train F1 score : 0.9671702980995178\n",
      "Train Confusion Matrix : \n",
      "tensor([[38875,  1898],\n",
      "        [  818, 40007]])\n",
      "Test F1 score : 0.9616336226463318\n",
      "Test Confusion Matrix : \n",
      "tensor([[9696,  530],\n",
      "        [ 261, 9913]])\n",
      "Train F1 score : 0.9682180285453796\n",
      "Train Confusion Matrix : \n",
      "tensor([[38956,  1817],\n",
      "        [  810, 40015]])\n",
      "Test F1 score : 0.9619024395942688\n",
      "Test Confusion Matrix : \n",
      "tensor([[9705,  521],\n",
      "        [ 264, 9910]])\n",
      "Train F1 score : 0.968874454498291\n",
      "Train Confusion Matrix : \n",
      "tensor([[39012,  1761],\n",
      "        [  810, 40015]])\n",
      "Test F1 score : 0.9620314836502075\n",
      "Test Confusion Matrix : \n",
      "tensor([[9711,  515],\n",
      "        [ 267, 9907]])\n",
      "Train F1 score : 0.9694305062294006\n",
      "Train Confusion Matrix : \n",
      "tensor([[39053,  1720],\n",
      "        [  804, 40021]])\n",
      "Test F1 score : 0.962056040763855\n",
      "Test Confusion Matrix : \n",
      "tensor([[9718,  508],\n",
      "        [ 273, 9901]])\n",
      "Train F1 score : 0.9702706336975098\n",
      "Train Confusion Matrix : \n",
      "tensor([[39116,  1657],\n",
      "        [  796, 40029]])\n",
      "Test F1 score : 0.9624659419059753\n",
      "Test Confusion Matrix : \n",
      "tensor([[9730,  496],\n",
      "        [ 276, 9898]])\n",
      "Train F1 score : 0.9710814356803894\n",
      "Train Confusion Matrix : \n",
      "tensor([[39169,  1604],\n",
      "        [  781, 40044]])\n",
      "Test F1 score : 0.9624586701393127\n",
      "Test Confusion Matrix : \n",
      "tensor([[9732,  494],\n",
      "        [ 278, 9896]])\n",
      "Train F1 score : 0.9718139171600342\n",
      "Train Confusion Matrix : \n",
      "tensor([[39210,  1563],\n",
      "        [  761, 40064]])\n",
      "Test F1 score : 0.9626349806785583\n",
      "Test Confusion Matrix : \n",
      "tensor([[9739,  487],\n",
      "        [ 281, 9893]])\n",
      "Train F1 score : 0.972410261631012\n",
      "Train Confusion Matrix : \n",
      "tensor([[39250,  1523],\n",
      "        [  751, 40074]])\n",
      "Test F1 score : 0.9627178311347961\n",
      "Test Confusion Matrix : \n",
      "tensor([[9744,  482],\n",
      "        [ 284, 9890]])\n",
      "Train F1 score : 0.9731330275535583\n",
      "Train Confusion Matrix : \n",
      "tensor([[39288,  1485],\n",
      "        [  729, 40096]])\n",
      "Test F1 score : 0.9631973505020142\n",
      "Test Confusion Matrix : \n",
      "tensor([[9751,  475],\n",
      "        [ 281, 9893]])\n"
     ]
    }
   ],
   "source": [
    "EPOCHES = 30\n",
    "\n",
    "for epoch in range(EPOCHES):\n",
    "    train(model, trainloader, optimizer, criterion, scheduler)\n",
    "    evaluate(model, testloader, criterion)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bareunpy\n",
      "  Downloading bareunpy-1.6.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting bareun-apis<0.13.0,>=0.12.0 (from bareunpy)\n",
      "  Downloading bareun_apis-0.12.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.0 (from bareunpy)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting grpcio<2.0.0,>=1.46.0 (from bareunpy)\n",
      "  Downloading grpcio-1.62.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting protobuf<4.0.0,>=3.19.4 (from bareunpy)\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (679 bytes)\n",
      "Downloading bareunpy-1.6.3-py3-none-any.whl (15 kB)\n",
      "Downloading bareun_apis-0.12.0-py3-none-any.whl (23 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, grpcio, googleapis-common-protos, bareun-apis, bareunpy\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.2\n",
      "    Uninstalling protobuf-4.25.2:\n",
      "      Successfully uninstalled protobuf-4.25.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.2.2 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cugraph 24.2.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cugraph 24.2.0 requires rapids-dask-dependency==24.2.*, which is not installed.\n",
      "cuml 24.2.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cuml 24.2.0 requires rapids-dask-dependency==24.2.*, which is not installed.\n",
      "cuxfilter 24.2.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 24.2.2 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 24.2.2 requires rapids-dask-dependency==24.2.*, which is not installed.\n",
      "cudf 24.2.2 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bareun-apis-0.12.0 bareunpy-1.6.3 googleapis-common-protos-1.63.0 grpcio-1.62.1 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install bareunpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
